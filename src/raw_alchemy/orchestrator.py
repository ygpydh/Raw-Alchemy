import os
import concurrent.futures
from raw_alchemy import core
try:
    from . import core
except ImportError:
    import core

# Supported RAW file extensions (lowercase)
SUPPORTED_RAW_EXTENSIONS = [
    '.dng', '.cr2', '.cr3', '.nef', '.arw', '.rw2', '.raf', '.orf', '.pef', '.srw'
]

def process_path(
    input_path,
    output_path,
    log_space,
    lut_path,
    exposure,
    lens_correct,
    custom_db_path,
    metering_mode,
    jobs,
    logger_func, # A function to handle logging, e.g., print or queue.put
    output_format: str = 'tif',
):
    """
    Orchestrates the processing of a single file or a directory of files.
    Updated to support GUI Progress Bar signaling.
    """
    
    # --- Helper Functions ---
    def log_message(msg):
        """å‘é€æ™®é€šæ–‡æœ¬æ—¥å¿—"""
        if hasattr(logger_func, 'put'):
            # å¦‚æœæ˜¯ GUI é˜Ÿåˆ—ï¼Œè¿™é‡Œå…¶å®å¯ä»¥åŒ…ä¸€å±‚ç»“æ„ï¼Œä¹Ÿå¯ä»¥å‘çº¯æ–‡æœ¬
            # è¿™é‡Œçš„ logger_func å°±æ˜¯ mp_queue
            logger_func.put(msg) 
        else:
            logger_func(msg)

    def send_signal(data):
        """å‘é€æ§åˆ¶ä¿¡å· (å­—å…¸)ï¼Œç”¨äºè¿›åº¦æ¡æ§åˆ¶"""
        if hasattr(logger_func, 'put'):
            logger_func.put(data)

    output_ext = f".{output_format}"

    # ============================
    #      Batch Processing
    # ============================
    if os.path.isdir(input_path):
        if not os.path.isdir(output_path):
            error_msg = "For batch processing, the output path must be a directory."
            log_message(f"âŒ Error: {error_msg}")
            raise ValueError(error_msg)

        raw_files = []
        for ext in SUPPORTED_RAW_EXTENSIONS:
            raw_files.extend([f for f in os.listdir(input_path) if f.lower().endswith(ext)])

        if not raw_files:
            log_message("âš ï¸ No supported RAW files found in the input directory.")
            raise ValueError("No RAW files found.")

        # ã€å…³é”®ä¿®æ”¹ 1ã€‘å‘é€æ€»æ–‡ä»¶æ•°ä¿¡å·ï¼Œé€šçŸ¥ GUI åˆå§‹åŒ–è¿›åº¦æ¡
        count = len(raw_files)
        log_message(f"ğŸ” Found {count} RAW files for parallel processing.")
        send_signal({'total_files': count}) 
        
        with concurrent.futures.ProcessPoolExecutor(max_workers=jobs) as executor:
            futures = {
                executor.submit(
                    core.process_image,
                    raw_path=os.path.join(input_path, filename),
                    output_path=os.path.join(output_path, f"{os.path.splitext(filename)[0]}{output_ext}"),
                    log_space=log_space,
                    lut_path=lut_path,
                    exposure=exposure,
                    lens_correct=lens_correct,
                    custom_db_path=custom_db_path,
                    metering_mode=metering_mode,
                    # Pass queue directly if it is one (for internal logging inside the worker)
                    log_queue=logger_func if hasattr(logger_func, 'put') else None 
                ): filename for filename in raw_files
            }
            
            for future in concurrent.futures.as_completed(futures):
                filename = futures[future]
                try:
                    future.result()  # Check for exceptions
                except Exception as exc:
                    log_msg = f"âŒ Generated an exception: {exc}"
                    if hasattr(logger_func, 'put'):
                        logger_func.put({'id': filename, 'msg': log_msg})
                    else:
                        log_message(f"[{filename}] {log_msg}")
                finally:
                    # ã€å…³é”®ä¿®æ”¹ 2ã€‘æ— è®ºæˆåŠŸè¿˜æ˜¯å¤±è´¥ï¼Œéƒ½å‘é€å®Œæˆä¿¡å·ï¼Œè®©è¿›åº¦æ¡å¾€å‰èµ°
                    send_signal({'status': 'done'})
        
        log_message("\nğŸ‰ Batch processing complete.")

    # ============================
    #    Single File Processing
    # ============================
    else:
        final_output_path = output_path
        if os.path.isdir(output_path):
            base_name = os.path.basename(input_path)
            file_name, _ = os.path.splitext(base_name)
            final_output_path = os.path.join(output_path, f"{file_name}{output_ext}")
        
        # å•æ–‡ä»¶ä¹Ÿå¯ä»¥çœ‹ä½œæ˜¯ total=1 çš„æ‰¹å¤„ç†ï¼Œè¿™æ ·è¿›åº¦æ¡èƒ½ç›´æ¥æ»¡
        send_signal({'total_files': 1})
        
        log_message("âš™ï¸ Processing single file...")
        try:
            core.process_image(
                raw_path=input_path,
                output_path=final_output_path,
                log_space=log_space,
                lut_path=lut_path,
                exposure=exposure,
                lens_correct=lens_correct,
                custom_db_path=custom_db_path,
                metering_mode=metering_mode,
                log_queue=logger_func if hasattr(logger_func, 'put') else None
            )
        finally:
            # å‘é€å®Œæˆä¿¡å·
            send_signal({'status': 'done'})
            
        log_message("\nğŸ‰ Single file processing complete.")